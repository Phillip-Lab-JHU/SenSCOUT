{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1260da33",
   "metadata": {},
   "source": [
    "# Imputation Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830bdd3",
   "metadata": {},
   "source": [
    "Here, we will walk through the imputation code to understand how we can leverage morphology to elicit protein biomarker expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d06554",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('\\\\path to raw morphological csv\\\\')\n",
    "#read in the dataframe with the excels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595651e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries                                                                             \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4a368",
   "metadata": {},
   "source": [
    "# Construct PCs from the morphological dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter_Excel=pd.read_excel('\\\\path to filtered morphological parameters csv\\\\')\n",
    "#morpho_params=communalities_sort['Parameter'].to_list()\n",
    "\n",
    "\n",
    "sorted_dataframe=DF['morpho_params'] #filter out morphological parameters of interest to construct the principal components\n",
    "\n",
    "pca=PCA(n_components=10, random_state=42) # start with ten PCs\n",
    "pca.fit(sorted_dataframe) # fit the model to the dataframe \n",
    "pca_values=pca.transform(sorted_dataframe) #transform the sorted dataframe into PCA space\n",
    "weights=np.array(pca.explained_variance_ratio_) # create weights based on the variance explained, want to keep PCs that cumulatively\n",
    "#explain 95% of the variance \n",
    "PC_DF=pd.DataFrame(pca_values, columns = ['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10'])\n",
    "# now lets concat the pandas dataframe with the PCs \n",
    "PC_DF.index = data.index\n",
    "data=pd.concat([data,PC_DF],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512c921",
   "metadata": {},
   "source": [
    "# Imputation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938e4b1",
   "metadata": {},
   "source": [
    "Below are a collection  of functions that will allow for the imputation of a biomarker on an individual cell basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_averaging_biomarker_values(distances,biomarkers): # this function takes a weighted average of biomarker expression from nearest PC neighbors \n",
    "\n",
    "    sum_distances=np.sum(distances) #sum of all distances\n",
    "    adjusted_weights=sum_distances/distances\n",
    "    \n",
    "    \n",
    "    \n",
    "    biomarker_weights=adjusted_weights/np.sum(adjusted_weights)\n",
    "    weighted_average=np.sum(np.multiply(biomarker_weights,biomarkers))\n",
    "    return weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_distance(x,y, weights): #custom distance with a weight function for every PC distance \n",
    "    q=x-y # distance between two points\n",
    "    return np.sqrt((weights*q*q).sum()) # calculates wieghted euclidian distance of PC variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5345a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biomarker_imputer(overall_dataframe, cell_ID, biomarker,batch_corrected_value,weights,average=True):\n",
    "    \n",
    "    #first lets sort by the cel_line, below sorts for the string sequence to sort\n",
    "\n",
    "    cell_row=overall_dataframe.loc[cell_ID]# sort the dataframe to the cell of interest\n",
    "\n",
    "    cell_line=cell_row['Cell Treatment Condition'].split('_')[0] #sort by same age line (I.e. Young_ATV will be split into 'Young')\n",
    "   \n",
    "    \n",
    "    #now lets do a series of filter steps to curate our excel sheet\n",
    "    #Sort the large dataframe by age determined from step above\n",
    "    Cell_sorted_dataframe=overall_dataframe[overall_dataframe['Cell Treatment Condition'].str.contains(cell_line)]\n",
    "    \n",
    "    \n",
    "    #sort by KMEANS, this will circumscribe our search of nearest neighbors \n",
    "    \n",
    "    Cell_sorted_dataframe=Cell_sorted_dataframe[Cell_sorted_dataframe['KMEANS']==cell_row['KMEANS']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #sort to find the biomarker of interest that is stained for \n",
    "    Cell_BM_sorted_dataframe= Cell_sorted_dataframe[Cell_sorted_dataframe['Primary Biomarker Stained']==biomarker_of_interest]\n",
    "\n",
    "\n",
    "\n",
    "    if cell_ID in Cell_BM_sorted_dataframe.index: # drop the cell _ID from the dataframe that is filtered (if we already know the value)\n",
    "        Cell_BM_sorted_dataframe=Cell_BM_sorted_dataframe.drop([cell_ID])\n",
    "\n",
    "    Final_KMEANS_DF=Cell_BM_sorted_dataframe.append(cell_row) # keep a version of the dataframe with the cell of interest\n",
    "    \n",
    "    \n",
    "\n",
    "    #store the index of interest\n",
    "    index_position = Final_KMEANS_DF.index.get_indexer([cell_ID])[0]\n",
    "    \n",
    "    #call the kmean neartest neighbors to get the indices of interest\n",
    "    nearest_neighbors,distances=knnearest_indices(Final_KMEANS_DF, weights,21)\n",
    "    #now sort the indices of interest\n",
    "    nearest_neighbors=nearest_neighbors[index_position]\n",
    "    distances=distances[index_position]\n",
    "    #now we will fitler the Final KMEANS by the sorted index position, and find their biomarker values (note these are batch corrected values)\n",
    "    biomarker_imputation=Final_KMEANS_DF.iloc[nearest_neighbors][batch_corrected_value].values\n",
    "    \n",
    "    #now we will impute based on either average or weighted averages\n",
    "    if average==False:\n",
    "        biomarker_imputation=weighted_averaging_biomarker_values(distances,biomarker_imputation)\n",
    "    else:\n",
    "        biomarker_imputation=np.average(biomarker_imputation)\n",
    "    \n",
    "    return biomarker_imputation\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f211d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find a cell_id of interest, and impute\n",
    "\n",
    "cell_ID='Bio1_0'\n",
    "Biomarker='P16'\n",
    "weights=np.array(pca.explained_variance_ratio_) \n",
    "\n",
    "imputed_biomarker=biomarker_imputer(data, cell_ID, Biomarker,'Primary Biomarker Batch Corrected',weights,average=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
